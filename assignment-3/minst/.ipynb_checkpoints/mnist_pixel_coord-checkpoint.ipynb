{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TRrtW63GQ_69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-mnist in c:\\users\\l\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install python-mnist\n",
    "# %pip install matplotlib\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqQUU1P1Q_7B"
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BMeHcv_fQ_7F"
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('dataset')\n",
    "\n",
    "x_train, y_train = mndata.load_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlayed = {i: [0] * 784 for i in range(10)}\n",
    "\n",
    "for image, cls_ in zip(x_train, y_train):\n",
    "    for idx, color in enumerate(image):        \n",
    "        overlayed[cls_][idx] += (color/255)\n",
    "\n",
    "# overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6511.984313725561\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "plt.imshow(np.array(overlayed[1]).reshape(28, 28))\n",
    "print(max(overlayed[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    flat = []\n",
    "\n",
    "    for item in array:\n",
    "        try:\n",
    "            iter(item)\n",
    "            flat.extend(flatten(item))\n",
    "        except:\n",
    "            flat.append(item)\n",
    "\n",
    "    return flat\n",
    "\n",
    "\n",
    "def reshape(array, rows, cols):\n",
    "    flat_array = flatten(array)\n",
    "\n",
    "    if rows * cols != len(flat_array):\n",
    "        raise Exception(f\"Can't reshape array to ({rows}, {cols})\")\n",
    "\n",
    "    reshaped = [[0] * cols for _ in range(rows)]    \n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            reshaped[row][col] = flat_array[row * cols + col]\n",
    "\n",
    "    return reshaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7SW47aUqQ_7F"
   },
   "outputs": [],
   "source": [
    "def prepare(image):\n",
    "    # image = reshape(image, 28, 28)\n",
    "\n",
    "    # output = []\n",
    "    \n",
    "    # # major diagonal\n",
    "    # for i in range(28):\n",
    "    #     output.append(image[i][i] / 255)\n",
    "    \n",
    "    # # minor diagonal\n",
    "    # for i in range(28):\n",
    "    #     output.append(image[27 - i][i] / 255)\n",
    "    \n",
    "    # # center horizontal    \n",
    "    # for i in range(28):\n",
    "    #     output.append(image[14][i] / 255)\n",
    "\n",
    "    # # center vertical\n",
    "    # for j in range(12, 18):\n",
    "    #     for i in range(28):        \n",
    "    #         output.append(image[i][j] / 255)\n",
    "    \n",
    "    # output.append(1)\n",
    "\n",
    "\n",
    "    # return output\n",
    "    image = image[:]\n",
    "       \n",
    "    for idx, color in enumerate(image):\n",
    "        image[idx] = color / 255\n",
    "    \n",
    "    # for the bias\n",
    "    image.append(1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "# append one feature  (for the bias term)\n",
    "\n",
    "x_train_normalized = []\n",
    "\n",
    "for image in x_train:\n",
    "    x_train_normalized.append(prepare(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtQT26EwQ_7G"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sGn5-guTQ_7I"
   },
   "outputs": [],
   "source": [
    "def sigmoid_scalar(x):\n",
    "    # to avoid overflow\n",
    "    if x < 0:\n",
    "      sigmoid = math.exp(x) / (1 + math.exp(x))\n",
    "    else:\n",
    "      sigmoid = 1 / (1 + math.exp(-x))\n",
    "\n",
    "    # to handle machine precision errors\n",
    "    sigmoid = max(0.0001, sigmoid)\n",
    "    sigmoid = min(0.9999, sigmoid)\n",
    "\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T9f7v-keQ_7I"
   },
   "outputs": [],
   "source": [
    "def argmax(values):\n",
    "    max_value = float('-inf')\n",
    "    max_index = 0\n",
    "\n",
    "    for idx, value in enumerate(values):\n",
    "        if value > max_value:\n",
    "            max_index = idx\n",
    "            max_value = value\n",
    "\n",
    "    return max_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q26D61H2Q_7J"
   },
   "outputs": [],
   "source": [
    "def predict(sample_x, weights):\n",
    "    # calculate z = sum(w * x + b)\n",
    "    # here bias (b) is also included in weights\n",
    "    z = 0\n",
    "    for x, w in zip(sample_x, weights):\n",
    "        z += w * x\n",
    "\n",
    "    # sigmoid(z)\n",
    "    return sigmoid_scalar(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wH64cwHIQ_7L"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(predicted_value, actual_value):\n",
    "    y = actual_value\n",
    "    y_pred = predicted_value    \n",
    "\n",
    "    if y == 1:        \n",
    "        return -math.log(y_pred)\n",
    "\n",
    "    else:        \n",
    "        return -math.log(1 - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wGX5WiTGQ_7L"
   },
   "outputs": [],
   "source": [
    "def gradient_decent(X, label, weights=None, learning_rate=0.1):\n",
    "    n_features = len(X[0])\n",
    "\n",
    "    # initialize weight with random values (equal length to x's features)\n",
    "    if weights == None:\n",
    "        weights = [random.random() for _ in range(n_features)]\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for x, y in zip(X, label):\n",
    "        y_pred = predict(x, weights)\n",
    "        loss += cross_entropy_loss(y_pred, y)\n",
    "\n",
    "        # dw = (y_pred - y) * x\n",
    "        # weight = weight - learning_rate * dw\n",
    "        err = y_pred - y\n",
    "        for i in range(n_features):\n",
    "            dw_i = err * x[i]\n",
    "            weights[i] -= learning_rate * dw_i\n",
    "\n",
    "    return weights, loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sndBLTHJQ_7M"
   },
   "outputs": [],
   "source": [
    "def train_binary_class(x_train, y_train, learning_rate, epoch, verbose=False):\n",
    "    weights = None\n",
    "\n",
    "    # for graphing\n",
    "    history = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        weights, loss = gradient_decent(x_train, y_train, weights, learning_rate)\n",
    "\n",
    "        history.append(loss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{i}]\\n\\t- Cross entropy loss: {loss}\\n\")\n",
    "\n",
    "    return weights, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qvqRd3ejQ_7N"
   },
   "outputs": [],
   "source": [
    "def train_multiclass(x_train, y_train, learning_rate, epoch, verbose=False):\n",
    "    # identify unique classes\n",
    "    classes = range(0, 10)\n",
    "\n",
    "    # for each class create separate labels suitable for binary classification\n",
    "    labels = [[] for _ in classes]\n",
    "\n",
    "    for class_ in classes:\n",
    "        for label in y_train:            \n",
    "            if label == class_:\n",
    "                labels[class_].append(1)\n",
    "\n",
    "            else:\n",
    "                labels[class_].append(0)\n",
    "    \n",
    "    # now that we have separate labels for each class\n",
    "    # lets train binary classifier for each class\n",
    "    # (each classifier will identify whether sample x is member of class or not)\n",
    "\n",
    "    # we have 10 classes so we need 10 binary classifiers\n",
    "    classifiers = [None] * 10\n",
    "    histories = [None] * 10\n",
    "\n",
    "    for cls_, label in enumerate(labels):\n",
    "        if verbose:\n",
    "            print(f'Training class [{cls_}]')\n",
    "\n",
    "        weights, history = train_binary_class(x_train, label, learning_rate, epoch)        \n",
    "\n",
    "        classifiers[cls_] = weights\n",
    "        histories[cls_] = history\n",
    "\n",
    "        if verbose:\n",
    "            print('---------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    return classifiers, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tgprAe-oQ_7P"
   },
   "outputs": [],
   "source": [
    "def predict_class(sample_x, model):\n",
    "    class_probabilities = []\n",
    "    \n",
    "    for weights in model:\n",
    "        class_probability = predict(sample_x, weights)\n",
    "        class_probabilities.append(class_probability)\n",
    "    \n",
    "    return argmax(class_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cCekxVigjWmy"
   },
   "outputs": [],
   "source": [
    "# sum([predict_class(x_train_normalized[i], model) == y_train[i] for i in range(60000)])\n",
    "\n",
    "def confusion_matrix(test_x, label, model):\n",
    "  print(test_x)\n",
    "  \n",
    "  grid = [[0] * 10 for _ in range(10)]\n",
    "  net_accuracy = 0\n",
    "\n",
    "  print(len(label))\n",
    "\n",
    "  for i in range(len(test_x)):\n",
    "    prediction = predict_class(test_x[i], model)\n",
    "    \n",
    "    actual = label[i]\n",
    "    \n",
    "    grid[prediction][actual] += 1\n",
    "    \n",
    "    if prediction == label[i]:\n",
    "      net_accuracy += 1              \n",
    "    \n",
    "  return grid, net_accuracy / len(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztPTVh2wQ_7Q"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIsesQrSQ_7Q",
    "outputId": "f2c4e808-c11a-48d2-c0a2-d1c4f6e279e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class [0]\n",
      "---------------------------------------------------------------------\n",
      "Training class [1]\n",
      "---------------------------------------------------------------------\n",
      "Training class [2]\n",
      "---------------------------------------------------------------------\n",
      "Training class [3]\n",
      "---------------------------------------------------------------------\n",
      "Training class [4]\n",
      "---------------------------------------------------------------------\n",
      "Training class [5]\n",
      "---------------------------------------------------------------------\n",
      "Training class [6]\n",
      "---------------------------------------------------------------------\n",
      "Training class [7]\n",
      "---------------------------------------------------------------------\n",
      "Training class [8]\n",
      "---------------------------------------------------------------------\n",
      "Training class [9]\n",
      "---------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.3995735679839469,\n",
       "  0.12830254922110235,\n",
       "  0.055457091207956125,\n",
       "  0.025257896061899696,\n",
       "  0.04679869423355501,\n",
       "  0.03180363887737216,\n",
       "  0.04336693521909601,\n",
       "  0.007478794680184139,\n",
       "  0.00010434948289761851,\n",
       "  0.00010683002313363516],\n",
       " [0.4758196569287432,\n",
       "  0.29125849311783314,\n",
       "  0.213500283708665,\n",
       "  0.1716859726592767,\n",
       "  0.07991965536565124,\n",
       "  0.05621036646703542,\n",
       "  0.07719784973480982,\n",
       "  0.00010456104890407907,\n",
       "  0.00010180115244171588,\n",
       "  0.00010069636015424502],\n",
       " [0.8386257147086416,\n",
       "  0.3155317340202878,\n",
       "  0.224767270435789,\n",
       "  0.017776515943893366,\n",
       "  0.006551384984873431,\n",
       "  0.00010437800237871002,\n",
       "  0.0001008981170752424,\n",
       "  0.000100466028947047,\n",
       "  0.0001015286164782966,\n",
       "  0.00010433167847898911],\n",
       " [0.6574310373548811,\n",
       "  0.21587611780310065,\n",
       "  0.0822871888875874,\n",
       "  0.10438742003578728,\n",
       "  0.06762703024900697,\n",
       "  0.016152883285556658,\n",
       "  0.0006482599645658067,\n",
       "  0.00011717574580451242,\n",
       "  0.00012227722832643646,\n",
       "  0.00012484063868468183],\n",
       " [0.5230193505241308,\n",
       "  0.15576390124514736,\n",
       "  0.16510039717241662,\n",
       "  0.06710641759498323,\n",
       "  0.041997772807475714,\n",
       "  0.010149488749747158,\n",
       "  0.00010192942494908138,\n",
       "  0.0001005177317991464,\n",
       "  0.00010147541593730672,\n",
       "  0.00010576843943345675],\n",
       " [0.6244312399827778,\n",
       "  0.4901363181195161,\n",
       "  0.34529272657816745,\n",
       "  0.2230451554862694,\n",
       "  0.27493580553480973,\n",
       "  0.1507935740564531,\n",
       "  0.13297238489748153,\n",
       "  0.15376546762602797,\n",
       "  0.058008086570587036,\n",
       "  0.131047015226882],\n",
       " [0.4782851112147515,\n",
       "  0.22722793122872714,\n",
       "  0.05046844771264192,\n",
       "  0.09762363410897554,\n",
       "  0.0006585592874584757,\n",
       "  0.00015863553643616569,\n",
       "  0.00010136069112410444,\n",
       "  0.00010021937251210056,\n",
       "  0.00010000500033334673,\n",
       "  0.00010000500033334673],\n",
       " [0.611830904234181,\n",
       "  0.30102008096954413,\n",
       "  0.1563593257294978,\n",
       "  0.15951487517203147,\n",
       "  0.11897040605239058,\n",
       "  0.04259902253390544,\n",
       "  0.08190836034218749,\n",
       "  0.0553237491814272,\n",
       "  0.02353302554508345,\n",
       "  0.0002051252283208376],\n",
       " [1.01474530525556,\n",
       "  0.3770274679878668,\n",
       "  0.4389592828373726,\n",
       "  0.376957712274586,\n",
       "  0.34679466525387004,\n",
       "  0.14777391406374724,\n",
       "  0.13080477586663228,\n",
       "  0.10826627604213525,\n",
       "  0.04566635434861615,\n",
       "  0.032454010577850544],\n",
       " [0.9007696239126924,\n",
       "  0.38368088288953167,\n",
       "  0.23501190310288506,\n",
       "  0.29941216300462964,\n",
       "  0.13541981900275182,\n",
       "  0.19456501910840954,\n",
       "  0.11408922042447135,\n",
       "  0.13533626869096024,\n",
       "  0.047208006974634904,\n",
       "  0.07149455292877915]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "train_size = 500\n",
    "\n",
    "x_train_set = x_train_normalized[:train_size]\n",
    "y_train_set = y_train[:train_size]\n",
    "\n",
    "x_validation_set = x_train_normalized[train_size:]\n",
    "y_validaiton_set = y_train[train_size:]\n",
    "\n",
    "model, history = train_multiclass(x_train_set, y_train_set, learning_rate, epochs, verbose=True)\n",
    "history\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GE_Rsyw1V0n9"
   },
   "outputs": [],
   "source": [
    "x_test, y_test = mndata.load_testing()\n",
    "\n",
    "x_test_normalized = []\n",
    "\n",
    "for image in x_test:          \n",
    "    x_test_normalized.append(prepare(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GwO1s9PKWS6k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "array index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# with open('learning_rate_[0.001].m', 'rb') as f:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#   model = pickle.load(f)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m matrix, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m accuracy\n",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(test_x, label, model)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_x)):\n\u001b[0;32m     12\u001b[0m   prediction \u001b[38;5;241m=\u001b[39m predict_class(test_x[i], model)\n\u001b[1;32m---> 14\u001b[0m   actual \u001b[38;5;241m=\u001b[39m \u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m   grid[prediction][actual] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m label[i]:\n",
      "\u001b[1;31mIndexError\u001b[0m: array index out of range"
     ]
    }
   ],
   "source": [
    "# with open('learning_rate_[0.001].m', 'rb') as f:\n",
    "#   model = pickle.load(f)\n",
    "\n",
    "matrix, accuracy = confusion_matrix(x_test_normalized, y_test[:500], model)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "HKgF5-4xfIqT",
    "outputId": "f02171aa-5492-4138-8dc5-77c65b2585ff"
   },
   "outputs": [],
   "source": [
    "plt.imshow(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
