{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4944b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c88d40",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8eb4a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, train_test_ratio=.8):\n",
    "    \n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()[1:]\n",
    "        \n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    x, y = [], []    \n",
    "        \n",
    "    for line in lines:                        \n",
    "        if 'NA' in line:\n",
    "            continue\n",
    "        \n",
    "        line = line.split(',')\n",
    "        \n",
    "        features = line[:4]\n",
    "        features[1] = float(features[1])\n",
    "        features[2] = float(features[2])\n",
    "        features[3] = float(features[3])                \n",
    "        \n",
    "        line[4] = 1 if line[4].strip() == '\"TRUE\"' else 0\n",
    "        \n",
    "        x.append(features)\n",
    "        y.append(line[4])\n",
    "    \n",
    "    train_set_size = int(len(x) * train_test_ratio)           \n",
    "    \n",
    "    train_x = x[:train_set_size]\n",
    "    train_y = y[:train_set_size]\n",
    "    test_x = x[train_set_size:]\n",
    "    test_y = y[train_set_size:]        \n",
    "    \n",
    "        \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "738671e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = read_csv('dataset/seattleWeather_1948-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e089ef75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 4.0, 0.0], [3.77, 103.0, 71.0])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect data for normalization\n",
    "\n",
    "mins = [float('inf')] * 3\n",
    "maxs = [float('-inf')] * 3\n",
    "\n",
    "for line in train_x:    \n",
    "    for i, value in enumerate(line[1:]):\n",
    "        mins[i] = min(mins[i], value)\n",
    "        maxs[i] = max(maxs[i], value)\n",
    "\n",
    "        \n",
    "mins, maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5fc4ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input\n",
    "\n",
    "def prepare(x):\n",
    "    x = x[1:]\n",
    "    \n",
    "#     for i in range(len(x)):\n",
    "#         x[i] = (x[i] - mins[i]) / (maxs[i] - mins[i])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f871ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normalized = []\n",
    "\n",
    "for x in train_x:\n",
    "    x_train_normalized.append(prepare(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a34c9e",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d9eb78d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 11722, 1: 8716}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count frequecy of each number in the dataset\n",
    "\n",
    "class_frequency = {0: 0, 1: 0}\n",
    "\n",
    "for label in y_train:\n",
    "    class_frequency[label] += 1\n",
    "\n",
    "class_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a969e86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5735394852725315, 1: 0.42646051472746843}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate prior\n",
    "\n",
    "prior = {}\n",
    "\n",
    "dataset_size = len(y_train)\n",
    "\n",
    "for class_ in range(2):\n",
    "    prior[class_] = class_frequency[class_] / dataset_size\n",
    "\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a1cf31d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {1: [0.04476367550640909, 25.390742734122714, 19.003278207260983],\n",
       "             0: [0.059696643507191234, 34.21019669243566, 25.534396712007045]})"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean and variance for each feature\n",
    "\n",
    "n_features = len(x_train_normalized[0])\n",
    "\n",
    "mean = defaultdict(lambda : [0] * n_features)\n",
    "\n",
    "for sample, label in zip(x_train_normalized, y_train):\n",
    "    for idx, feature in enumerate(sample):\n",
    "        mean[label][idx] += feature\n",
    "        \n",
    "for value in mean.values():\n",
    "    for idx in range(len(value)):\n",
    "        value[idx] /= dataset_size\n",
    "\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c2451a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {1: [0.024435435047548693, 565.7207896297342, 312.2166759398423],\n",
       "             0: [0.03354310616114135, 465.6540190718237, 252.27214590873672]})"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# varience\n",
    "\n",
    "varience = defaultdict(lambda : [0] * n_features)\n",
    "\n",
    "for sample, label in zip(x_train_normalized, y_train):\n",
    "    for idx, feature in enumerate(sample):\n",
    "        varience[label][idx] += (feature - mean[label][idx]) ** 2\n",
    "\n",
    "        \n",
    "for value in varience.values():\n",
    "    for idx in range(len(value)):\n",
    "        value[idx] /= dataset_size  \n",
    "\n",
    "varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "9234dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gausian_probability(xs, mean, var, smoothing):\n",
    "    probability = []\n",
    "        \n",
    "    for idx, x in enumerate(xs):\n",
    "        m = mean[idx]\n",
    "        v = var[idx] + smoothing\n",
    "        \n",
    "        prob = 1 / math.sqrt(2 * math.pi * v) * math.exp(-(x - m) ** 2 / (2 * v))            \n",
    "        \n",
    "        probability.append(math.log(prob))\n",
    "    \n",
    "    return sum(probability)\n",
    "\n",
    "\n",
    "def argmax(values):\n",
    "    max_value = float('-inf')\n",
    "    max_index = 0\n",
    "\n",
    "    for idx, value in enumerate(values):\n",
    "        if value > max_value:\n",
    "            max_index = idx\n",
    "            max_value = value\n",
    "\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "adb16812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(sample, smoothing):    \n",
    "    gaussians_likelihood = [0] * 2\n",
    "    \n",
    "    for cls in range(2):\n",
    "        m = mean[cls]\n",
    "        var = varience[cls]\n",
    "        \n",
    "        probability = gausian_probability(sample, m, var, smoothing)               \n",
    "        \n",
    "        probability += math.log(prior[cls])\n",
    "        \n",
    "        gaussians_likelihood[cls] = probability        \n",
    "    \n",
    "    return argmax(gaussians_likelihood)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "72960ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test, y_test, smoothing):    \n",
    "    confussion_matrix = [[0] * 2 for _ in range(2)]\n",
    "    net_accuracy = 0\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        prediction = predict_naive_bayes(x_test[i], smoothing)\n",
    "\n",
    "        confussion_matrix[prediction][y_test[i]] += 1\n",
    "\n",
    "        if prediction == y_test[i]:\n",
    "            net_accuracy += 1\n",
    "\n",
    "    return confussion_matrix, net_accuracy / len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a6d51e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "smoothings = [0.01, 0.1, 0.5, 1.0, 10, 100]\n",
    "\n",
    "x_test_normalized = list(map(prepare, x_test))\n",
    "\n",
    "scores = []\n",
    "\n",
    "for smoothing in smoothings:\n",
    "    cm, acc = test(x_test_normalized, y_test, smoothing)\n",
    "    \n",
    "    scores.append((cm, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3cabf85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAByCAYAAAAPvZi2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAK2UlEQVR4nO3dXWxb9RnH8Z+dNs6AxJBFTWqREl5Kq66b0cpSdepFQZ66IhWYtAmhaYpyUU2I3pC73pDL3KFqJVIlJFR2wzoxNUwMVRuBKtrWKpDUrAgItITWUhYnGW3iGuokzn8XUc2yNiTHfuzjl+9HOhc5qnMef4PQ02PXCTjnnAAAAAwE/R4AAABUDxYLAABghsUCAACYYbEAAABmWCwAAIAZFgsAAGCGxQIAAJjZUOoLLi0taWJiQo2NjQoEAqW+fNlyzimVSikSiSgY9Lbv0fT2aFoc+Xal6epoao+m9tbd1JVYIpFwkjhWORKJBE1pWhGH1640pSlNq+NYq2nJ71g0NjZKki6PdqjpLv9fiflt4qd+jyBJWkjP69STf8z18aLcmh66stfvESQtN33zqT/Q1Fi+XWm6Oprao6m99TYt+WJx89ZS011BNTX6/0PbeGe93yOskM+tN5p+N5oWh9euNF0bTe3R1N5aTf2vBgAAqgaLBQAAMMNiAQAAzLBYAAAAMywWAADADIsFAAAww2IBAADMsFgAAAAzLBYAAMAMiwUAADDDYgEAAMzktVj09/ero6NDDQ0N2r17t4aHh63nqjmfD4xJkjZt2kRTIxff/FQSTS199sbHevvXf5IkPf744zQ1QFN7NPWX58Xi5MmT6unpUW9vr0ZHRxWNRrV//35NTU0VY76a8OXfvtCHx0ckSUNDQzQ1cPmdS/rX8Q8k0dTK5Xcu6fzvzmnHb6KSpJ07d9K0QDS1R1P/eV4sXnrpJR06dEjd3d3asWOHjh8/rjvuuEOvvvpqMearCZ++/pEeeOIhSdL27dtpamDs9Y90/xNbJdHUytjrH+nBJ7er4+fL/60ePXqUpgWiqT2a+s/TYjE/P6+RkRHFYrFvv0EwqFgsprNnz972MZlMRnNzcysOfCu7kNVXY/9R6483587RtDDLTWe0iaZmbjZt+0kkd46mhaGpPZqWB0+LxczMjLLZrFpbW1ecb21t1eTk5G0f09fXp3A4nDva29vzn7YKZa5l5LJOoXsaVpynaf4y127IZZ0a7vneivM0zV+uaTNNrdDUHk3LQ9H/VciRI0c0OzubOxKJRLEvWfVoao+m9mhqj6b2aGpvg5c/3NLSorq6OiWTyRXnk8mk2trabvuYUCikUCiU/4RVLnR3SIG6gDJXb6w4T9P8he5uUKAuoBtXv1lxnqb5yzX96huFH7gnd56m+aOpPZqWB093LOrr67Vr1y4NDg7mzi0tLWlwcFB79uwxH64W1G2sU/O27yt5/tvbdDQtzHLTFk2N/jt3jqaFudl08oOJ3DmaFoam9mhaHjy/FNLT06NXXnlFr732mj755BM999xzSqfT6u7uLsZ8NWH7szv1xV8+lySNjY3R1MC2Z3dq/G2aWtr27E5d+vOYvvzrJUnSCy+8QNMC0dQeTf3n6aUQSXrmmWc0PT2tF198UZOTk3rkkUd0+vTpW97QifXr+NkD+noqrfPH3tfevXtpauC+2IP6OplW/OVhmhq5L/agMldv6OMTcUnShQsXaFogmtqjqf88LxaSdPjwYR0+fNh6lpq29eltOn/sfU1PT6upqcnvcarCQ09vV/zlYZoaevhXP9D9T2zVG7Hf691336WrAZrao6m/+F0hAADADIsFAAAww2IBAADMsFgAAAAzLBYAAMAMiwUAADDDYgEAAMywWAAAADMsFgAAwAyLBQAAMJPXR3pb+MXDP9SGwEa/Lv8/5vweQJK06BYK/h7l0/Sa3wNIommxFNqVpreiqT2a2ltvU+5YAAAAMywWAADADIsFAAAww2IBAADMsFgAAAAzLBYAAMAMiwUAADDDYgEAAMywWAAAADMsFgAAwAyLBQAAMMNiAQAAzLBYAAAAMywWAADAjOfFYmhoSAcPHlQkElEgENDAwEARxqotV920LuicJCkcDtPUAE3tXXXTirt/6J86LUl66623fJ6o8tHUHk3953mxSKfTikaj6u/vL8Y8NSmrRd2psN9jVBWa2stqUXcprK36kd+jVA2a2qOp/zZ4fcCBAwd04MCBYsxSs1oCm3W3a9EVfeb3KFWDpvZaApvVos1adAt+j1I1aGqPpv7zvFh4lclklMlkcl/Pzc0V+5JVj6b2aGqPpvZoao+m9or+5s2+vj6Fw+Hc0d7eXuxLVj2a2qOpPZrao6k9mtor+mJx5MgRzc7O5o5EIlHsS1Y9mtqjqT2a2qOpPZraK/pLIaFQSKFQqNiXqSk0tUdTezS1R1N7NLXH51gAAAAznheL69evKx6PKx6PS5LGx8cVj8d15coV69lqxqJbVEqzua9pWjia2lt0i0q5a7muly9fpmmBaGqPpv4LOOeclwecOXNGjz322C3nu7q6dOLEiTUfPzc3p3A4rH16ShsCG71cump95aY0qqFbztM0fzS1R1N7NLVH0+JZdAs6ozc1OzurpqamVf+c5/dY7Nu3Tx53EayhObBJ+9xT6/qBYX1oaq85sEkx/XLd/3PB2mhqj6b+4z0WAADADIsFAAAww2IBAADMsFgAAAAzLBYAAMAMiwUAADDDYgEAAMywWAAAADMsFgAAwEzRf7vp/7v5qZ2LWpD4AM+cRS1IUl6fakrT26NpceTblaaro6k9mtpbb9OSLxapVEqS9He9XepLV4RUKqVwOOz5MRJNV0PT4vDalaZro6k9mtpbq6nnX0JWqKWlJU1MTKixsVGBQCCv7zE3N6f29nYlEomy+Ax4i3mcc0qlUopEIgoGvb1CRdPbo2lx5sm3K01XR1P7eWhqP896m5b8jkUwGNS9995r8r2amprK4od2U6HzeP1b9U00XR1Nb2UxTz5dafrdaLoSTe2Vqilv3gQAAGZYLAAAgJmKXCxCoZB6e3sVCoX8HkVS+c2Tj3J7DuU2Tz7K7TmU2zz5KLfnUG7z5KPcnkO5zZOPcnsOpZ6n5G/eBAAA1asi71gAAIDyxGIBAADMsFgAAAAzLBYAAMAMiwUAADBTkYtFf3+/Ojo61NDQoN27d2t4eNiXOYaGhnTw4EFFIhEFAgENDAz4MocFmtqjqT2a2qOpvVpvWnGLxcmTJ9XT06Pe3l6Njo4qGo1q//79mpqaKvks6XRa0WhU/f39Jb+2JZrao6k9mtqjqT2aSnIVprOz0z3//PO5r7PZrItEIq6vr8/HqZyT5E6dOuXrDPmiqT2a2qOpPZrao6lzFXXHYn5+XiMjI4rFYrlzwWBQsVhMZ8+e9XGyykVTezS1R1N7NLVH02UVtVjMzMwom82qtbV1xfnW1lZNTk76NFVlo6k9mtqjqT2a2qPpsopaLAAAQHmrqMWipaVFdXV1SiaTK84nk0m1tbX5NFVlo6k9mtqjqT2a2qPpsopaLOrr67Vr1y4NDg7mzi0tLWlwcFB79uzxcbLKRVN7NLVHU3s0tUfTZRv8HsCrnp4edXV16dFHH1VnZ6eOHj2qdDqt7u7uks9y/fp1Xbx4Mff1+Pi44vG4mpubtWXLlpLPky+a2qOpPZrao6k9mqry/rmpc84dO3bMbdmyxdXX17vOzk537tw5X+Z47733nKRbjq6uLl/mKQRN7dHUHk3t0dRerTcNOOdc8dYWAABQSyrqPRYAAKC8sVgAAAAzLBYAAMAMiwUAADDDYgEAAMywWAAAADMsFgAAwAyLBQAAMMNiAQAAzLBYAAAAMywWAADAzH8BXh3ve5eeLuUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw confussion matrix\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(smoothings))\n",
    "    \n",
    "for i, ax in enumerate(axs.flat):\n",
    "    \n",
    "    ax.set_label(smoothings[i])\n",
    "\n",
    "    ax.imshow(scores[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d7caaa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing: 0.01 \tAccuracy: 0.5718199608610568\n",
      "Smoothing: 0.1 \tAccuracy: 0.5726027397260274\n",
      "Smoothing: 0.5 \tAccuracy: 0.5726027397260274\n",
      "Smoothing: 1.0 \tAccuracy: 0.5727984344422701\n",
      "Smoothing: 10 \tAccuracy: 0.5727984344422701\n",
      "Smoothing: 100 \tAccuracy: 0.5727984344422701\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    print(f'Smoothing: {smoothings[i]} \\tAccuracy: {scores[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f79e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55275ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
