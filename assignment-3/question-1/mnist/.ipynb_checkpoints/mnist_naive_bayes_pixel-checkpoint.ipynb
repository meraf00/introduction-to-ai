{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de77d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-mnist\n",
    "# %pip install matplotlib\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e2fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('dataset')\n",
    "\n",
    "x_train, y_train = mndata.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dda6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    flat = []\n",
    "\n",
    "    for item in array:\n",
    "        try:\n",
    "            iter(item)\n",
    "            flat.extend(flatten(item))\n",
    "        except:\n",
    "            flat.append(item)\n",
    "\n",
    "    return flat\n",
    "\n",
    "def reshape(array, rows, cols):\n",
    "    flat_array = flatten(array)\n",
    "\n",
    "    if rows * cols != len(flat_array):\n",
    "        raise Exception(f\"Can't reshape array to ({rows}, {cols})\")\n",
    "\n",
    "    reshaped = [[0] * cols for _ in range(rows)]    \n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            reshaped[row][col] = flat_array[row * cols + col]\n",
    "\n",
    "    return reshaped\n",
    "\n",
    "def prepare(image):\n",
    "    image = reshape(image, 28, 28)\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    # major diagonal\n",
    "    for i in range(28):\n",
    "        output.append(image[i][i] / 255)\n",
    "    \n",
    "    # minor diagonal\n",
    "    for i in range(28):\n",
    "        output.append(image[27 - i][i] / 255)\n",
    "    \n",
    "    # center horizontal ( 3 pixels)\n",
    "    for j in range(13, 16):\n",
    "        for i in range(28):        \n",
    "            output.append(image[j][i] / 255)\n",
    "\n",
    "    # center vertical    ( 3 pixels) \n",
    "    for j in range(13, 16):\n",
    "        for i in range(28):        \n",
    "            output.append(image[i][j] / 255)\n",
    "\n",
    "\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2de8d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "x_train_normalized = []\n",
    "\n",
    "for image in x_train:\n",
    "    x_train_normalized.append(prepare(image))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6449b",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59241859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count frequecy of each number in the dataset\n",
    "\n",
    "class_frequency = {i:0 for i in range(10)}\n",
    "\n",
    "for label in y_train:\n",
    "    class_frequency[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a55532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prior\n",
    "\n",
    "prior = {}\n",
    "\n",
    "dataset_size = len(y_train)\n",
    "\n",
    "for class_ in range(10):\n",
    "    prior[class_] = class_frequency[class_] / dataset_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbe872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and variance for each pixels\n",
    "\n",
    "mean = defaultdict(lambda : [0] * 784)\n",
    "\n",
    "for image, label in zip(x_train_normalized, y_train):\n",
    "    for pixel_idx, pixel in enumerate(image):\n",
    "        mean[label][pixel_idx] += pixel\n",
    "\n",
    "        \n",
    "for value in mean.values():\n",
    "    for idx in range(len(value)):\n",
    "        value[idx] /= dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18052f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# varience\n",
    "\n",
    "varience = defaultdict(lambda : [0] * 784)\n",
    "\n",
    "for image, label in zip(x_train_normalized, y_train):\n",
    "    for pixel_idx, pixel in enumerate(image):\n",
    "        varience[label][pixel_idx] += (pixel - mean[label][pixel_idx]) ** 2\n",
    "\n",
    "        \n",
    "for value in varience.values():\n",
    "    for idx in range(len(value)):\n",
    "        value[idx] /= dataset_size                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da18572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw mean of pixels\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10)\n",
    "    \n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "    ax.imshow(reshape(mean[i], 28, 28))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw varience of pixels\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10)\n",
    "    \n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.yaxis.set_tick_params(labelleft=False)\n",
    "    \n",
    "    ax.imshow(reshape(varience[i], 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gausian_probability(xs, mean, var, smoothing):\n",
    "    probability = []\n",
    "        \n",
    "    for idx, x in enumerate(xs):\n",
    "        m = mean[idx]\n",
    "        v = var[idx] + smoothing\n",
    "        \n",
    "        prob = 1 / math.sqrt(2 * math.pi * v) * math.exp(-(x - m) ** 2 / (2 * v))            \n",
    "        \n",
    "        probability.append(math.log(prob))\n",
    "    \n",
    "    return sum(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2733d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(image, smoothing):    \n",
    "    gaussians_likelihood = [0] * 10\n",
    "    \n",
    "    for cls in range(10):\n",
    "        m = mean[cls]\n",
    "        var = varience[cls]\n",
    "        \n",
    "        probability = gausian_probability(image, m, var, smoothing)               \n",
    "        \n",
    "        probability += math.log(prior[cls])\n",
    "        \n",
    "        gaussians_likelihood[cls] = probability\n",
    "    \n",
    "    return argmax(gaussians_likelihood)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf523a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test, y_test, smoothing):    \n",
    "    confussion_matrix = [[0] * 10 for _ in range(10)]\n",
    "    net_accuracy = 0\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        prediction = predict_naive_bayes(x_test[i], smoothing)\n",
    "\n",
    "        confussion_matrix[prediction][y_test[i]] += 1\n",
    "\n",
    "        if prediction == y_test[i]:\n",
    "            net_accuracy += 1\n",
    "\n",
    "    return confussion_matrix, net_accuracy / len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "smoothings = [0.01, 0.1, 0.5, 1.0, 10, 100]\n",
    "\n",
    "x_test, y_test = mndata.load_testing()\n",
    "\n",
    "x_test_normalized = list(map(prepare, x_test))\n",
    "\n",
    "scores = []\n",
    "\n",
    "for smoothing in smoothings:\n",
    "    cm, acc = test(x_test_normalized, y_test, smoothing)\n",
    "    \n",
    "    scores.append((cm, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764600c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw confussion matrix\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(smoothings))\n",
    "    \n",
    "for i, ax in enumerate(axs.flat):\n",
    "    \n",
    "    ax.set_label(smoothings[i])\n",
    "\n",
    "    ax.imshow(scores[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    print(f'Smoothing: {smoothings[i]} \\tAccuracy: {scores[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20c0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
